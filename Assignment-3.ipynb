{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**INFT1204: Special Topics in Cybersecurity - Assignment 3**\n",
        "\n",
        "**Group Members: Hammed Tijani (ID:100902204), Tehara Moonemalle (ID: 100903984), Steffannie Egbuziem (ID:100896975), Romoyne Watson (ID: 100895321).**\n",
        "\n",
        "Code attribution:\n",
        "\n",
        "*   https://www.analyticsvidhya.com/blog/2021/09/performing-email-spam-detection-using-bert-in-python/\n",
        "*   https://github.com/prateekjoshi565/Fine-Tuning-BERT/blob/master/Fine_Tuning_BERT_for_Spam_Classification.ipynb\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SZ7R0QMTZllu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Packages**"
      ],
      "metadata": {
        "id": "D4Utf2uJ4yl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"tensorflow==2.8.*\"\n",
        "!pip install -U \"tensorflow-text==2.8.*\"\n",
        "!pip install transformers\n",
        "!pip install -U tensorflow-text\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "!pip install gradio\n",
        "!pip install fsspec==2022.10.0"
      ],
      "metadata": {
        "id": "Hr1JiJNPR9gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Packages**"
      ],
      "metadata": {
        "id": "MkK8Ia_F5G0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import tensorflow_text as text\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast, AutoModelForSequenceClassification, TrainingArguments\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "SXBBAnAyQ055"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the Dataset**"
      ],
      "metadata": {
        "id": "895zwKtn5Oob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "df = pd.read_csv('/content/Data/spam.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "lLvAJTkoRAHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check count and unique and top values and their frequency\n",
        "df['Category'].value_counts()"
      ],
      "metadata": {
        "id": "FDFXlDcqUAMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check percentage of data - states how much data needs to be balanced\n",
        "print(str(round(747/4825,2))+'%')"
      ],
      "metadata": {
        "id": "C8HCOvAnUCjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating a new dataset with equal data for each Category**"
      ],
      "metadata": {
        "id": "DZl4YbHS5Xcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating 2 new dataframe as df_phishing, df_not_phishing\n",
        "\n",
        "df_phishing = df[df['Category']=='phishing']\n",
        "\n",
        "df_not_phishing = df[df['Category']=='not phishing']\n",
        "\n",
        "print(\"Not Phishing Dataset Shape:\", df_not_phishing.shape)\n",
        "\n",
        "print(\"Phishing Dataset Shape:\", df_phishing.shape)"
      ],
      "metadata": {
        "id": "wS5NHm_LUIrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downsampling not phishing dataset - take only random 747 example\n",
        "# will use df_phishing.shape[0] - 747\n",
        "df_nphishing_downsampled = df_not_phishing.sample(df_phishing.shape[0])\n",
        "df_nphishing_downsampled.shape"
      ],
      "metadata": {
        "id": "lEtQ7zCkUgoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concating both dataset - df_phishing and df_nphishing_downsampled to create df_balanced dataset\n",
        "df_balanced = pd.concat([df_phishing , df_nphishing_downsampled])\n",
        "\n",
        "df_balanced['Category'].value_counts()"
      ],
      "metadata": {
        "id": "9Cug_bnPVR9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_balanced.sample(10)"
      ],
      "metadata": {
        "id": "980FvnnFVnlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating numerical repersentation of category - one hot encoding\n",
        "df_balanced['Type'] = df_balanced['Category'].apply(lambda x:1 if x=='phishing' else 0)\n",
        "\n",
        "# displaying data - phishing -1 , not phishing-0\n",
        "df_balanced.sample(4)"
      ],
      "metadata": {
        "id": "NfosYhXTV0NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training and Testing Dataset**"
      ],
      "metadata": {
        "id": "Y_2R3nSJ5kW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test , y_train, y_test = train_test_split(df_balanced['Message'], df_balanced['Type'],\n",
        "                                                    stratify = df_balanced['Type'])"
      ],
      "metadata": {
        "id": "2ZWxoQEwWKDK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download BERT**"
      ],
      "metadata": {
        "id": "dMbP4a7Y5zNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading preprocessing files and model\n",
        "bert_preprocessor = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
        "bert_encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4')"
      ],
      "metadata": {
        "id": "pViRUgcBWX6L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training using Keras API**"
      ],
      "metadata": {
        "id": "DcNCUPBh54P7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training using the Keras API\n",
        "text_input = tf.keras.layers.Input(shape = (), dtype = tf.string, name = 'Inputs')\n",
        "preprocessed_text = bert_preprocessor(text_input)\n",
        "embeed = bert_encoder(preprocessed_text)\n",
        "dropout = tf.keras.layers.Dropout(0.1, name = 'Dropout')(embeed['pooled_output'])\n",
        "outputs = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'Dense')(dropout)\n",
        "# creating final model\n",
        "model = tf.keras.Model(inputs = [text_input], outputs = [outputs])"
      ],
      "metadata": {
        "id": "lCRrrGG5XuXj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "LQ40Tbowb6_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Metrics = [tf.keras.metrics.BinaryAccuracy(name = 'accuracy'),\n",
        "           tf.keras.metrics.Precision(name = 'precision'),\n",
        "           tf.keras.metrics.Recall(name = 'recall')\n",
        "           ]\n",
        "# compiling our model\n",
        "model.compile(optimizer ='adam',\n",
        "               loss = 'binary_crossentropy',\n",
        "               metrics = Metrics)"
      ],
      "metadata": {
        "id": "NVfGPOWicC92"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 10)"
      ],
      "metadata": {
        "id": "gWU_uq9gctUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating performance\n",
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "_p4heo7v4shq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradio Interface**"
      ],
      "metadata": {
        "id": "I3VWGtjX6CAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spam_filter(email):\n",
        "    test_results = model.predict([email])  # Assuming model.predict() accepts a list of emails\n",
        "    output = np.where(test_results > 0.5, 'phishing', 'not phishing')\n",
        "    return output[0][0]\n",
        "\n",
        "# Define the interface\n",
        "demo = gr.Interface(\n",
        "    fn=spam_filter,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Email Here...\"),\n",
        "    outputs=[gr.Textbox(label=\"output\")],\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "8mO66Qwvkw-U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}